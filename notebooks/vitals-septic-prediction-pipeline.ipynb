{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515ee907-6815-4c31-a66e-965e468dfccc",
   "metadata": {},
   "source": [
    "# TFX Keras Component Tutorial to predict Sepsis from patient vitals data\n",
    "\n",
    "A Component-by-Component Introduction to TensorFlow Extended (TFX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151158e-dfd3-4b7f-8125-27828af07242",
   "metadata": {},
   "source": [
    "Note: In this notebook, we can instantiate components one-by-one and run them with InteractiveContext.run(). By contrast, in a production setting, we would specify all the components upfront in a Pipeline to pass to the orchestrator (see the Building a TFX Pipeline Guide). https://www.tensorflow.org/tfx/guide/build_tfx_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db53f467-785b-46fa-8b24-0cba25dc92ec",
   "metadata": {},
   "source": [
    "# Connect to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8a8c35-fc01-42c1-9fcd-ff7ac2db49c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit this section using your own credentials\n",
    "s3_region = 'us-east-2' # fill in for AWS, blank for Ceph\n",
    "s3_endpoint_url = 'https://s3.storage.server'\n",
    "s3_access_key_id = '<enter>'\n",
    "s3_secret_access_key = '<enter>'\n",
    "s3_bucket = 'patient-vitals-labeled'\n",
    "\n",
    "import boto3\n",
    "\n",
    "# configure boto S3 connection\n",
    "s3 = boto3.client('s3',\n",
    "                  s3_region,\n",
    "                  #endpoint_url = s3_endpoint_url,\n",
    "                  aws_access_key_id = s3_access_key_id,\n",
    "                  aws_secret_access_key = s3_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fb7052-55d1-4a95-88ae-05234213c70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'WZ70HAP3WSG11KDE',\n",
       "  'HostId': '1dw2AoKi2lIOg5zyFN1DzkcDR3xjlRMA8HphA+LXwGkJAjz+yg3Gu/hbKmKXaUCSkJ/K7GgtHRk=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '1dw2AoKi2lIOg5zyFN1DzkcDR3xjlRMA8HphA+LXwGkJAjz+yg3Gu/hbKmKXaUCSkJ/K7GgtHRk=',\n",
       "   'x-amz-request-id': 'WZ70HAP3WSG11KDE',\n",
       "   'date': 'Wed, 18 May 2022 16:54:18 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'a-team-test-bucket-capital',\n",
       "   'CreationDate': datetime.datetime(2022, 5, 18, 16, 31, 13, tzinfo=tzlocal())},\n",
       "  {'Name': 'cluster-cghmd-ph8fx-image-registry-us-east-2-phaylcmbaqujkubsy',\n",
       "   'CreationDate': datetime.datetime(2022, 4, 9, 14, 17, 47, tzinfo=tzlocal())},\n",
       "  {'Name': 'nb.1651759466492.cluster-cghmd.cghmd.sandbox879.opentlc.com',\n",
       "   'CreationDate': datetime.datetime(2022, 5, 5, 14, 7, 8, tzinfo=tzlocal())},\n",
       "  {'Name': 'patient-vitals-labeled',\n",
       "   'CreationDate': datetime.datetime(2022, 5, 17, 20, 46, 10, tzinfo=tzlocal())}],\n",
       " 'Owner': {'ID': 'd117504ba5a7ea71375f9297ef57018f34a1969f4f1335193e78e63fc0fbda0b'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88447b6e-0b34-40c0-9d5f-bda102bdf183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3.create_bucket(Bucket=\"a-team-test-bucket-capital\", CreateBucketConfiguration={'LocationConstraint': \"us-east-2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84135867-b2d5-4d9c-8310-52ade63f6148",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "import urllib\n",
    "import tensorboard\n",
    "\n",
    "import absl\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "tf.get_logger().propagate = False\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1a6cd5-0c77-4ab1-a253-b4fa86249289",
   "metadata": {},
   "source": [
    "# Check Versions\n",
    "Expecting\n",
    "- TensorFlow version: 2.8.0\n",
    "- TFX version: 1.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8638c6fa-ae17-47f1-9578-9ea45e9cf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "print('TFX version: {}'.format(tfx.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6407e5d8-2849-46b6-afb1-f4fe6221e0d0",
   "metadata": {},
   "source": [
    "# Setup pipeline paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089508d9-779e-48e5-b1e3-8cbd9d72dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the root directory for your TFX pip package installation.\n",
    "_tfx_root = tfx.__path__[0]\n",
    "\n",
    "# This is the directory containing the TFX Vitals Pipeline example.\n",
    "_vitals_root = os.path.join(_tfx_root, '../pipeline/vitals')\n",
    "\n",
    "# This is the path where your model will be pushed for serving.\n",
    "_serving_model_dir = '../models/vitals_simple'\n",
    "\n",
    "# Set up logging.\n",
    "absl.logging.set_verbosity(absl.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56860dfe-3e76-47d0-b344-7c18d429977a",
   "metadata": {},
   "source": [
    "# Fetch training data and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b637b1-9428-4ee9-b95b-7e79f77d761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_attr_root = '../data/attributes'\n",
    "\n",
    "#ATTR_PATH = 'https://raw.githubusercontent.com/redhat-na-ssa/mlops-prototype/main/origin_data/edit_raw/csv_format/attribute_definitions.csv'\n",
    "#_attr_filepath = os.path.join(_attr_root, \"attr_definitions.csv\")\n",
    "#urllib.request.urlretrieve(ATTR_PATH, _attr_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6cc7b7-767a-4d0e-adcf-1eef1349f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "_attr_filepath = '.'\n",
    "_attr_data = \"attribute_definitions.csv\"\n",
    "s3.download_file(s3_bucket, \"data/attribute_definitions.csv\", _attr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bbb82d-5c1d-40b0-8a99-bb19cbef9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_data_root = '../data/raw'\n",
    "#DATA_PATH = 'https://raw.githubusercontent.com/redhat-na-ssa/mlops-prototype/main/origin_data/edit_raw/csv_format/pat_vitals_labeled-dataSepsis.csv'\n",
    "#_data_filepath = os.path.join(_data_root, \"data.csv\")\n",
    "#urllib.request.urlretrieve(DATA_PATH, _data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54e361-2bfc-4c90-ae43-4bec5c72fc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data_root = '.'\n",
    "_data_raw = \"pat_vitals_labeled-dataSepsis.csv\"\n",
    "s3.download_file(s3_bucket, \"data/pat_vitals_labeled-dataSepsis.csv\", _data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6210d5-7bd6-4618-abc6-8d87dc0faa0d",
   "metadata": {},
   "source": [
    "# View the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3aa10b-39ce-43a8-a5fb-58f5cf20666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the attributes about the vitals data\n",
    "!head {_attr_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0e3ef8-644e-4181-9d65-32f977809b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the actual patient data with sepsis labels\n",
    "# 1 = septic, 0 = not-septic\n",
    "!head {_data_raw}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be7311-d4b2-4256-bfbd-77bf369a874f",
   "metadata": {},
   "source": [
    "# Create the Interactive Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7254449a-0ea8-4b06-a86e-57e45fc719da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we create an InteractiveContext using default parameters. This will\n",
    "# use a temporary directory with an ephemeral ML Metadata database instance.\n",
    "# To use your own pipeline root or database, the optional properties\n",
    "# `pipeline_root` and `metadata_connection_config` may be passed to\n",
    "# InteractiveContext. Calls to InteractiveContext are no-ops outside of the\n",
    "# notebook.\n",
    "context = InteractiveContext(pipeline_root='../pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a41dd-1ab9-4d95-b629-77007f8da739",
   "metadata": {},
   "source": [
    "# ExampleGen\n",
    "- The ExampleGen component is usually at the start of a TFX pipeline. It will:\n",
    "- Split data into training and evaluation sets (by default, 2/3 training + 1/3 eval)\n",
    "- Convert data into the tf.Example format\n",
    "- Copy data into the _tfx_root directory for other components to access ExampleGen takes as input the path to your data source. In our case, this is the _data_root path that contains the downloaded CSV.\n",
    "\n",
    "## Enable Cache\n",
    "When using the InteractiveContext in a notebook to develop a pipeline you can control when individual components will cache their outputs. \n",
    "1. Set enable_cache to True when you want to reuse the previous output artifacts that the component generated. \n",
    "1. Set enable_cache to False when you want to recompute the output artifacts for a component, if you are making changes to the code for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a035e-ce1e-49f8-bb17-fdc071aefb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_gen = tfx.components.CsvExampleGen(input_base=_data_root)\n",
    "context.run(example_gen, enable_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e51cc-2d5d-45f2-80dd-65c423288f5c",
   "metadata": {},
   "source": [
    "## Examine ExampleGen artifacts. \n",
    "This component produces two artifacts, training examples and evaluation examples: 'train' 'eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda36de-21b2-46e3-ac13-428dc2bf3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = example_gen.outputs['examples'].get()[0]\n",
    "print(artifact.split_names, artifact.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed074f9-89c3-49d6-b6ba-7c41bf7f4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URI of the output artifact representing the training examples, which is a directory\n",
    "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'Split-train')\n",
    "\n",
    "# Get the list of files in this directory (all compressed TFRecord files)\n",
    "tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                      for name in os.listdir(train_uri)]\n",
    "\n",
    "# Create a `TFRecordDataset` to read these files\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "\n",
    "# Iterate over the first 3 records and decode them.\n",
    "for tfrecord in dataset.take(3):\n",
    "  serialized_example = tfrecord.numpy()\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(serialized_example)\n",
    "  pp.pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee778469-e770-4f5c-990f-5839ee3ef631",
   "metadata": {},
   "source": [
    "# StatisticsGen\n",
    "\n",
    "- The StatisticsGen component computes statistics over your dataset for data analysis, as well as for use in downstream components. \n",
    "- It uses the TensorFlow Data Validation library.\n",
    "- StatisticsGen takes as input the dataset we just ingested using ExampleGen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab89965-36d3-400b-bb44-b9474140a052",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_gen = tfx.components.StatisticsGen(\n",
    "    examples=example_gen.outputs['examples'])\n",
    "context.run(statistics_gen, enable_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3366d8-842b-40c7-ba93-3184c4b7ce84",
   "metadata": {},
   "source": [
    "## Examine StatisticsGen artifacts.\n",
    "We can visualize the outputted statistics. Try playing with the different plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444b9e2-9dca-4633-9af3-82ac24ac205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(statistics_gen.outputs['statistics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575aa3b4-7405-4311-8463-64bca6c38946",
   "metadata": {},
   "source": [
    "# SchemaGen\n",
    "\n",
    "The SchemaGen component generates a schema based on your data statistics. \n",
    "- (A schema defines the expected bounds, types, and properties of the features in your dataset.) \n",
    "- It also uses the TensorFlow Data Validation library.\n",
    "- Note: The generated schema is best-effort and only tries to infer basic properties of the data. It is expected that you review and modify it as needed.\n",
    "- SchemaGen will take as input the statistics that we generated with StatisticsGen, looking at the training split by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016f097-4052-4e8e-85e5-565fd2e1619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_gen = tfx.components.SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=False)\n",
    "context.run(schema_gen, enable_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c948bb-bb25-4720-a973-228fa2e5f1bf",
   "metadata": {},
   "source": [
    "## Examine SchemaGen artifacts.\n",
    "\n",
    "After SchemaGen finishes running, we can visualize the generated schema as a table.\n",
    "- Each feature in your dataset shows up as a row in the schema table, alongside its properties. \n",
    "- The schema also captures all the values that a categorical feature takes on, denoted as its domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d8db8-e8d9-4a74-8a8d-eabbb3821264",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(schema_gen.outputs['schema'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c0ed4-8e78-4e64-91ca-0491f2ccc54d",
   "metadata": {},
   "source": [
    "# ExampleValidator\n",
    "\n",
    "The ExampleValidator component detects anomalies in your data, based on the expectations defined by the schema. \n",
    "- It also uses the TensorFlow Data Validation library.\n",
    "- ExampleValidator will take as input the statistics from StatisticsGen, and the schema from SchemaGen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765910ad-cbf7-4c0c-93b8-357bf3d776e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_validator = tfx.components.ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'])\n",
    "context.run(example_validator, enable_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0557b8-c8cb-4f12-83bd-8bd6cc974fc1",
   "metadata": {},
   "source": [
    "## Examine ExampleValidator artifacts.\n",
    "After ExampleValidator finishes running, we can visualize the anomalies as a table.\n",
    "\n",
    "In the anomalies table, we can see that there are no anomalies. This is what we'd expect, since this the first dataset that we've analyzed and the schema is tailored to it. You should review this schema -- anything unexpected means an anomaly in the data. Once reviewed, the schema can be used to guard future data, and anomalies produced here can be used to debug model performance, understand how your data evolves over time, and identify data errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6979ec-ab90-4267-b5ec-8106287cdfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(example_validator.outputs['anomalies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccfa61f-f7ef-42b0-bb7b-0f0a90e39b1b",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "The Transform component performs feature engineering for both training and serving. \n",
    "- It uses the TensorFlow Transform library.\n",
    "- Transform will take as input the data from ExampleGen, the schema from SchemaGen, as well as a module that contains user-defined Transform code.\n",
    "\n",
    "Note: The %%writefile cell magic will save the contents of the cell as a .py file on disk. This allows the Transform component to load your code as a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ff4a4-4ca1-4666-b2b1-b05e13172f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_vitals_constants_module_file = '../code/vitals_constants.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0474b-50c3-41b6-b3b4-b4b2c30fdf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_vitals_constants_module_file}\n",
    "\n",
    "NUMERICAL_FEATURES = ['HR', 'Resp', 'Temp']\n",
    "\n",
    "# Keys\n",
    "LABEL_KEY = 'isSepsis'\n",
    "\n",
    "def t_name(key):\n",
    "  \"\"\"\n",
    "  Rename the feature keys so that they don't clash with the raw keys when\n",
    "  running the Evaluator component.\n",
    "  Args:\n",
    "    key: The original feature key\n",
    "  Returns:\n",
    "    key with '_xf' appended\n",
    "  \"\"\"\n",
    "  return key + '_xf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238db4c-db79-4dd4-8986-a5d3dcb83453",
   "metadata": {},
   "source": [
    "## Data Preprocessing function\n",
    "\n",
    "Next, we write a preprocessing_fn that takes in raw data as input, and returns transformed features that our model can train on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014a643-0270-4ed5-8b10-1d5e84baa4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_vitals_transform_module_file = '../code/vitals_transform.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780480ef-b631-4124-9ac4-214951540fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_vitals_transform_module_file}\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "# Imported files such as vitals_constants are normally cached, so changes are\n",
    "# not honored after the first import.  Normally this is good for efficiency, but\n",
    "# during development when we may be iterating code it can be a problem. To\n",
    "# avoid this problem during development, reload the file.\n",
    "import vitals_constants\n",
    "import sys\n",
    "import importlib\n",
    "importlib.reload(vitals_constants)\n",
    "\n",
    "_NUMERICAL_FEATURES = vitals_constants.NUMERICAL_FEATURES\n",
    "_LABEL_KEY = vitals_constants.LABEL_KEY\n",
    "\n",
    "\n",
    "def _fill_in_missing(x):\n",
    "  \"\"\"Replace missing values in a SparseTensor.\n",
    "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
    "  Args:\n",
    "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
    "      in the second dimension.\n",
    "  Returns:\n",
    "    A rank 1 tensor where missing values of `x` have been filled in.\n",
    "  \"\"\"\n",
    "  if not isinstance(x, tf.sparse.SparseTensor):\n",
    "    return x\n",
    "\n",
    "  default_value = '' if x.dtype == tf.string else 0\n",
    "  return tf.squeeze(\n",
    "      tf.sparse.to_dense(\n",
    "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
    "          default_value),\n",
    "      axis=1)\n",
    "\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
    "  Args:\n",
    "    inputs: map from feature keys to raw not-yet-transformed features.\n",
    "  Returns:\n",
    "    Map from string feature key to transformed feature operations.\n",
    "  \"\"\"\n",
    "  outputs = {}\n",
    "  for key in _NUMERICAL_FEATURES:\n",
    "    # If sparse make it dense, setting nan's to 0 or '', and apply zscore.\n",
    "    outputs[vitals_constants.t_name(key)] = tft.scale_to_z_score(\n",
    "        _fill_in_missing(inputs[key]), name=key)\n",
    "\n",
    "  outputs[_LABEL_KEY] = _fill_in_missing(inputs[_LABEL_KEY]) \n",
    "    \n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc53fe-e21a-4c60-b2a0-3d4a196665d9",
   "metadata": {},
   "source": [
    "## Transform data with Preprocessing func.\n",
    "Now, we pass in this feature engineering code to the Transform component and run it to transform your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2842dd4-cf62-43df-8d4f-cb22c858cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfx.components.Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    module_file=os.path.abspath(_vitals_transform_module_file))\n",
    "context.run(transform, enable_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9e0a7-03b9-40d2-ad2d-1bcabc8b9654",
   "metadata": {},
   "source": [
    "## Examine Transform artifacts. \n",
    "This component produces two types of outputs:\n",
    "1. transform_graph is the graph that can perform the preprocessing operations (this graph will be included in the serving and evaluation models).\n",
    "1. transformed_examples represents the preprocessed training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba941ed-c856-4ab5-afbb-98ee34594f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e494a39-2d11-42d1-9b5d-66f2b3681efc",
   "metadata": {},
   "source": [
    "### Examine the Transform graph artifacts.\n",
    "\n",
    "1. The transformed_metadata subdirectory contains the schema of the preprocessed data. \n",
    "1. The transform_fn subdirectory contains the actual preprocessing graph. \n",
    "1. The metadata subdirectory contains the schema of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b0525-a01e-4d7a-9e4a-4500f42b09c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uri = transform.outputs['transform_graph'].get()[0].uri\n",
    "os.listdir(train_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353aea72-b017-4bae-9480-9369a05bdabd",
   "metadata": {},
   "source": [
    "### Examine some transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eba5cc-3cc2-4a21-88cf-e65e31d298c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
    "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'Split-train')\n",
    "\n",
    "# Get the list of files in this directory (all compressed TFRecord files)\n",
    "tfrecord_filenames = [os.path.join(train_uri, name)\n",
    "                      for name in os.listdir(train_uri)]\n",
    "\n",
    "# Create a `TFRecordDataset` to read these files\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "\n",
    "# Iterate over the first 1 records and decode them.\n",
    "for tfrecord in dataset.take(1):\n",
    "  serialized_example = tfrecord.numpy()\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(serialized_example)\n",
    "  pp.pprint(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb82245-f70f-46ea-964f-2be014ebf3b7",
   "metadata": {},
   "source": [
    "After the Transform component has transformed your data into features, and the next step is to train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49954bb6-8f58-4482-a120-3072760e653f",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "\n",
    "The Trainer component will train a model that you define in TensorFlow. \n",
    "- Default Trainer support Estimator API, to use Keras API, you need to specify Generic Trainer by setup custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor) in Trainer's contructor.\n",
    "- Trainer takes as input the schema from SchemaGen, the transformed data and graph from Transform, training parameters, as well as a module that contains user-defined model code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee38e1-b53a-4164-ac40-531e7fee75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_vitals_trainer_module_file = '../code/vitals_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d9f5d-3352-4b7b-a433-d63aae1fdbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {_vitals_trainer_module_file}\n",
    "\n",
    "from typing import Dict, List, Text\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from absl import logging\n",
    "\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "from tensorflow_transform import TFTransformOutput\n",
    "\n",
    "# Imported files such as vitals_constants are normally cached, so changes are\n",
    "# not honored after the first import.  Normally this is good for efficiency, but\n",
    "# during development when we may be iterating code it can be a problem. To\n",
    "# avoid this problem during development, reload the file.\n",
    "import vitals_constants\n",
    "import sys\n",
    "import importlib\n",
    "importlib.reload(vitals_constants)\n",
    "\n",
    "_LABEL_KEY = vitals_constants.LABEL_KEY\n",
    "\n",
    "_BATCH_SIZE = 40\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[Text],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              tf_transform_output: tft.TFTransformOutput,\n",
    "              batch_size: int = 200) -> tf.data.Dataset:\n",
    "  \"\"\"Generates features and label for tuning/training.\n",
    "\n",
    "  Args:\n",
    "    file_pattern: List of paths or patterns of input tfrecord files.\n",
    "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
    "    tf_transform_output: A TFTransformOutput.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      tf_transform_output.transformed_metadata.schema)\n",
    "\n",
    "def _get_tf_examples_serving_signature(model, tf_transform_output):\n",
    "  \"\"\"Returns a serving signature that accepts `tensorflow.Example`.\"\"\"\n",
    "\n",
    "  # We need to track the layers in the model in order to save it.\n",
    "  # TODO(b/162357359): Revise once the bug is resolved.\n",
    "  model.tft_layer_inference = tf_transform_output.transform_features_layer()\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None], dtype=tf.string, name='examples')\n",
    "  ])\n",
    "  def serve_tf_examples_fn(serialized_tf_example):\n",
    "    \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "    raw_feature_spec = tf_transform_output.raw_feature_spec()\n",
    "    # Remove label feature since these will not be present at serving time.\n",
    "    raw_feature_spec.pop(_LABEL_KEY)\n",
    "    raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n",
    "    transformed_features = model.tft_layer_inference(raw_features)\n",
    "    logging.info('serve_transformed_features = %s', transformed_features)\n",
    "\n",
    "    outputs = model(transformed_features)\n",
    "    # TODO(b/154085620): Convert the predicted labels from the model using a\n",
    "    # reverse-lookup (opposite of transform.py).\n",
    "    return {'outputs': outputs}\n",
    "\n",
    "  return serve_tf_examples_fn\n",
    "\n",
    "\n",
    "def _get_transform_features_signature(model, tf_transform_output):\n",
    "  \"\"\"Returns a serving signature that applies tf.Transform to features.\"\"\"\n",
    "\n",
    "  # We need to track the layers in the model in order to save it.\n",
    "  # TODO(b/162357359): Revise once the bug is resolved.\n",
    "  model.tft_layer_eval = tf_transform_output.transform_features_layer()\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None], dtype=tf.string, name='examples')\n",
    "  ])\n",
    "  def transform_features_fn(serialized_tf_example):\n",
    "    \"\"\"Returns the transformed_features to be fed as input to evaluator.\"\"\"\n",
    "    raw_feature_spec = tf_transform_output.raw_feature_spec()\n",
    "    raw_features = tf.io.parse_example(serialized_tf_example, raw_feature_spec)\n",
    "    transformed_features = model.tft_layer_eval(raw_features)\n",
    "    logging.info('eval_transformed_features = %s', transformed_features)\n",
    "    return transformed_features\n",
    "\n",
    "  return transform_features_fn\n",
    "\n",
    "\n",
    "def export_serving_model(tf_transform_output, model, output_dir):\n",
    "  \"\"\"Exports a keras model for serving.\n",
    "  Args:\n",
    "    tf_transform_output: Wrapper around output of tf.Transform.\n",
    "    model: A keras model to export for serving.\n",
    "    output_dir: A directory where the model will be exported to.\n",
    "  \"\"\"\n",
    "  # The layer has to be saved to the model for keras tracking purpases.\n",
    "  model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "  signatures = {\n",
    "      'serving_default':\n",
    "          _get_tf_examples_serving_signature(model, tf_transform_output),\n",
    "      'transform_features':\n",
    "          _get_transform_features_signature(model, tf_transform_output),\n",
    "  }\n",
    "\n",
    "  model.save(output_dir, save_format='tf', signatures=signatures)\n",
    "\n",
    "\n",
    "def _build_keras_model(tf_transform_output: TFTransformOutput\n",
    "                       ) -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying vitals data.\n",
    "\n",
    "  Args:\n",
    "    tf_transform_output: [TFTransformOutput], the outputs from Transform\n",
    "\n",
    "  Returns:\n",
    "    A keras Model.\n",
    "  \"\"\"\n",
    "  feature_spec = tf_transform_output.transformed_feature_spec().copy()\n",
    "  feature_spec.pop(_LABEL_KEY)\n",
    "\n",
    "  inputs = {}\n",
    "  for key, spec in feature_spec.items():\n",
    "    if isinstance(spec, tf.io.VarLenFeature):\n",
    "      inputs[key] = tf.keras.layers.Input(\n",
    "          shape=[None], name=key, dtype=spec.dtype, sparse=True)\n",
    "    elif isinstance(spec, tf.io.FixedLenFeature):\n",
    "      # TODO(b/208879020): Move into schema such that spec.shape is [1] and not\n",
    "      # [] for scalars.\n",
    "      inputs[key] = tf.keras.layers.Input(\n",
    "          shape=spec.shape or [1], name=key, dtype=spec.dtype)\n",
    "    else:\n",
    "      raise ValueError('Spec type is not supported: ', key, spec)\n",
    "  \n",
    "  output = tf.keras.layers.Concatenate()(tf.nest.flatten(inputs))\n",
    "  output = tf.keras.layers.Dense(100, activation='relu')(output)\n",
    "  output = tf.keras.layers.Dense(70, activation='relu')(output)\n",
    "  output = tf.keras.layers.Dense(50, activation='relu')(output)\n",
    "  output = tf.keras.layers.Dense(20, activation='relu')(output)\n",
    "  output = tf.keras.layers.Dense(1)(output)\n",
    "  return tf.keras.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "\n",
    "  train_dataset = _input_fn(fn_args.train_files, fn_args.data_accessor, \n",
    "                            tf_transform_output, _BATCH_SIZE)\n",
    "  eval_dataset = _input_fn(fn_args.eval_files, fn_args.data_accessor, \n",
    "                           tf_transform_output, _BATCH_SIZE)\n",
    "\n",
    "  model = _build_keras_model(tf_transform_output)\n",
    "\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "      metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=fn_args.model_run_dir, update_freq='batch')\n",
    "\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps,\n",
    "      callbacks=[tensorboard_callback])\n",
    "\n",
    "  # Export the model.\n",
    "  export_serving_model(tf_transform_output, model, fn_args.serving_model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48944460-34ee-4746-9abb-f366bf760b8e",
   "metadata": {},
   "source": [
    "## Train the model.\n",
    "\n",
    "Now, we pass in this model code to the Trainer component and run it to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706055c-f658-4468-873a-491631b82933",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = tfx.components.Trainer(\n",
    "    module_file=os.path.abspath(_vitals_trainer_module_file),\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    train_args=tfx.proto.TrainArgs(num_steps=10000),\n",
    "    eval_args=tfx.proto.EvalArgs(num_steps=5000))\n",
    "context.run(trainer, enable_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691cd45-7603-4041-bb20-15000698444a",
   "metadata": {},
   "source": [
    "## Analyze model with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d5a3b7-8d94-4f47-a512-b0b2973e668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact_dir = trainer.outputs['model'].get()[0].uri\n",
    "pp.pprint(os.listdir(model_artifact_dir))\n",
    "model_dir = os.path.join(model_artifact_dir, 'Format-Serving')\n",
    "pp.pprint(os.listdir(model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc64a85-4696-462f-ba7f-52f587259529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Tensorboard timesout and doesnt load\n",
    "\n",
    "model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "# The %tensorboard magic has exactly the same format as the TensorBoard command line invocation, but with a %-sign in front of it.\n",
    "%tensorboard --logdir {model_run_artifact_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3996bb3-929a-49d5-98d8-d0d5e8d7f19c",
   "metadata": {},
   "source": [
    "# Evaluator\n",
    "\n",
    "The Evaluator component computes model performance metrics over the evaluation set. \n",
    "- It uses the TensorFlow Model Analysis library. \n",
    "- The Evaluator can also optionally validate that a newly trained model is better than the previous model. \n",
    "- This is useful in a production pipeline setting where you may automatically train and validate a model every day.\n",
    "- In this notebook, we only train one model, so the Evaluator automatically will label the model as \"good\".\n",
    "\n",
    "Evaluator will take as input the data from ExampleGen, the trained model from Trainer, and slicing configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94935db2-dc5c-4611-b4b0-78dd80b9e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported files such as vitals_constants are normally cached, so changes are\n",
    "# not honored after the first import.  Normally this is good for efficiency, but\n",
    "# during development when we may be iterating code it can be a problem. To\n",
    "# avoid this problem during development, reload the file.\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "import vitals_constants\n",
    "import importlib\n",
    "importlib.reload(vitals_constants)\n",
    "\n",
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[\n",
    "        # This assumes a serving model with signature 'serving_default'. If\n",
    "        # using estimator based EvalSavedModel, add signature_name: 'eval' and\n",
    "        # remove the label_key.\n",
    "        tfma.ModelSpec(\n",
    "            signature_name='serving_default',\n",
    "            label_key=vitals_constants.LABEL_KEY,\n",
    "            preprocessing_function_names=['transform_features'],\n",
    "            )\n",
    "        ],\n",
    "    metrics_specs=[\n",
    "        tfma.MetricsSpec(\n",
    "            # The metrics added here are in addition to those saved with the\n",
    "            # model (assuming either a keras model or EvalSavedModel is used).\n",
    "            # Any metrics added into the saved model (for example using\n",
    "            # model.compile(..., metrics=[...]), etc) will be computed\n",
    "            # automatically.\n",
    "            # To add validation thresholds for metrics saved with the model,\n",
    "            # add them keyed by metric name to the thresholds map.\n",
    "            metrics=[\n",
    "                tfma.MetricConfig(class_name='ExampleCount'),\n",
    "                tfma.MetricConfig(class_name='BinaryAccuracy',\n",
    "                  threshold=tfma.MetricThreshold(\n",
    "                      value_threshold=tfma.GenericValueThreshold(\n",
    "                          lower_bound={'value': 0.5}),\n",
    "                      # Change threshold will be ignored if there is no\n",
    "                      # baseline model resolved from MLMD (first run).\n",
    "                      change_threshold=tfma.GenericChangeThreshold(\n",
    "                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
    "                          absolute={'value': -1e-10})))\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    slicing_specs=[\n",
    "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
    "        tfma.SlicingSpec(),\n",
    "        # Data can be sliced along a feature column. In this case, data is\n",
    "        # sliced along feature column HR.\n",
    "        tfma.SlicingSpec(\n",
    "            feature_keys=['HR'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32762ac5-6a58-4abf-801b-da02b6998ffb",
   "metadata": {},
   "source": [
    "## Run Evaluator\n",
    "Next, we give this configuration to Evaluator and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e96ec-7434-4916-8ac1-a3880f97c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TFMA to compute a evaluation statistics over features of a model and\n",
    "# validate them against a baseline.\n",
    "\n",
    "# The model resolver is only required if performing model validation in addition\n",
    "# to evaluation. In this case we validate against the latest blessed model. If\n",
    "# no model has been blessed before (as in this case) the evaluator will make our\n",
    "# candidate the first blessed model.\n",
    "model_resolver = tfx.dsl.Resolver(\n",
    "      strategy_class=tfx.dsl.experimental.LatestBlessedModelStrategy,\n",
    "      model=tfx.dsl.Channel(type=tfx.types.standard_artifacts.Model),\n",
    "      model_blessing=tfx.dsl.Channel(\n",
    "          type=tfx.types.standard_artifacts.ModelBlessing)).with_id(\n",
    "              'latest_blessed_model_resolver')\n",
    "context.run(model_resolver, enable_cache=True)\n",
    "\n",
    "evaluator = tfx.components.Evaluator(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    model=trainer.outputs['model'],\n",
    "    baseline_model=model_resolver.outputs['model'],\n",
    "    eval_config=eval_config)\n",
    "context.run(evaluator, enable_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42348d53-3987-48df-8e03-fe80d54a742a",
   "metadata": {},
   "source": [
    "## Examine Evaluator artifacts.\n",
    "\n",
    "Now let's examine the output artifacts of Evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7fa579-6872-4aa8-982d-d28ba3fe6659",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc2ef1-f1f8-45c4-84a4-cd201bbc0ebc",
   "metadata": {},
   "source": [
    "Using the evaluation output we can show the default visualization of global metrics on the entire evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a265579-bbb8-4d9c-b6c8-a0886a515e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.show(evaluator.outputs['evaluation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0018317-7670-4cc8-99eb-e9200bd274d3",
   "metadata": {},
   "source": [
    "To see the visualization for sliced evaluation metrics, we can directly call the TensorFlow Model Analysis library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54958d01-056e-4899-8df0-c807eddcc99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_analysis as tfma\n",
    "\n",
    "# Get the TFMA output result path and load the result.\n",
    "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
    "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
    "\n",
    "# Show data sliced along feature column HR.\n",
    "tfma.view.render_slicing_metrics(\n",
    "    tfma_result, slicing_column='HR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94a445-fc4e-4c1e-9b00-dd124387c0bf",
   "metadata": {},
   "source": [
    "This visualization shows the same metrics, but computed at every feature value of HR instead of on the entire evaluation set.\n",
    "\n",
    "TensorFlow Model Analysis supports many other visualizations, such as Fairness Indicators and plotting a time series of model performance. To learn more, see https://www.tensorflow.org/guide/keras/sequential_model\n",
    "\n",
    "Since we added thresholds to our config, validation output is also available. The precence of a blessing artifact indicates that our model passed validation. Since this is the first validation being performed the candidate is automatically blessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5282ef-a302-4703-87dc-024c3201af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blessing_uri = evaluator.outputs['blessing'].get()[0].uri\n",
    "!ls -l {blessing_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353bd8da-7bbb-44e4-9904-99b379f28fc3",
   "metadata": {},
   "source": [
    "Now can also verify the success by loading the validation result record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1470e2-4d0a-4ef6-9963-6ea0b4019ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
    "print(tfma.load_validation_result(PATH_TO_RESULT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e0bd6-3358-42bc-a128-ec0aaa9c4ad3",
   "metadata": {},
   "source": [
    "# Pusher\n",
    "\n",
    "The Pusher component is usually at the end of a TFX pipeline. It checks whether a model has passed validation, and if so, exports the model to _serving_model_dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00884afb-fdf6-405f-b8d7-9eef2feccaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher = tfx.components.Pusher(\n",
    "    model=trainer.outputs['model'],\n",
    "    model_blessing=evaluator.outputs['blessing'],\n",
    "    push_destination=tfx.proto.PushDestination(\n",
    "        filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "            base_directory=_serving_model_dir)))\n",
    "context.run(pusher, enable_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ddcd13-428c-4f4e-861f-eebba4ef30cb",
   "metadata": {},
   "source": [
    "## Examine Pusher artifacts.\n",
    "\n",
    "Let's examine the output artifacts of Pusher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de906655-89e3-41c4-95e3-9b6ce25765b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ce260-de74-41af-8dbf-46706a06d5d2",
   "metadata": {},
   "source": [
    "In particular, the Pusher will export your model in the SavedModel format, which looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec0981-a835-472b-8798-62fb24d000e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "push_uri = pusher.outputs['pushed_model'].get()[0].uri\n",
    "model = tf.saved_model.load(push_uri)\n",
    "\n",
    "for item in model.signatures.items():\n",
    "  pp.pprint(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073473ec-0f0e-424a-a051-1376a92c9e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
